
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="RB5 ROBOTICS TUTORIALS">
    <title>(2) April Tag Feature Detection - RB5 ROBOTICS TUTORIALS</title>
    <meta name="author" content="RB5 ROBOTICS TUTORIALS">
    
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"RB5 ROBOTICS TUTORIALS","sameAs":[],"image":"avl-letters.png"},"articleBody":"An important task in robotics is to uniquely identify features and landmarks over time as a robot navigates through the environment. The process can help estimate the robotics position (localization) to ultimately be able to perform robust path planning and navigation. In this tutorial, we will explore a popular open-source library for AprilTag detection and 3D pose estimation from a single monorcular camera. \nAprilTags (shown in the figure below) are a form of fiducial markers that are designed with predefined sizes and patterns. The benefit of knowing their size is pose estimation given that a perspective mapping between two planes can be described by a Homography $\\mathbf{H}$ matrix. In this case, $\\mathbf{H}$ can describe a mapping between the camera frame and the marker since both can be assumed to be flat surfaces. This makes AprilTags an easy way of performing 3D pose estimation of objects with a single monocular camera by simply placing an AprilTag on the object. In addition, the unique pattern that defines each marker can help differentiate multiple markers that may be observable at a particular instance and by leveraging the concept of Hamming distance and dictionaries, error detection and correction can be performed in the event that part of a marker is occluded.\nMultiple AprilTag fiducial markers detected within an image with IDs 7 and 237. For marker 7, an error is detected and corrected. [1]\nThe AprilTag3 LibraryUsing the AprilTag library is actually quite simple and can be installed from source. This includes compatible versions for C++ but also Python3. While our implementation will consist of C++, the Python version is even easier to get up and running. To install, simply run pip install apriltag.\nFor convenience, we have provided two implementations for AprilTag detection in ROS1 and ROS2. Given that both are C++ implementations, the logic remains the same. First, we convert our image to grayscale and populate a image_u8_t struct using the OpenCV cv::Mat image format. \n12345678cv::Mat image_gray; cv::cvtColor(image, image_gray, cv::COLOR_BGR2GRAY);image_u8_t im = &#123; .width  = image_gray.cols,.height = image_gray.rows,.stride = image_gray.cols, .buf    = image_gray.data &#125;;\n\n Once the image has been converted to grayscale, we can instantiate an apriltag_detection_t instance and call apriltag_detector_detect(). This is the primary function incharge of performing marker detection on camera data. It is worth noting that this detection object can be reused so memory can be allocated in the class constructor of your implementation.\n12apriltag_detector_t *a_detector = apriltag_detector_create();zarray_t * detections = apriltag_detector_detect(a_detector, &amp;im);\n\nAs it can be seen, apriltag_detector_detect() returns an array of type zarray_t with the list of detections concatenated. In the following code block we extract individual detections into instances of type apriltag_detection_t and perform a perspective mapping using the homography matrix calculated. This is handled by estimate_tag_pose(). However, two important considerations include i) that we know the size of the markers in advance, and ii) we understand the intrinsic parameters of the camera that include image center and focal length. These are attributes that are part of the first argument of type apriltag_detection_info_t that is passed to estimate_tag_pose(). \n123456789101112131415apriltag_detection_t *det;vector&lt;apriltag_pose_t&gt; poses;vector&lt;int&gt; ids;for (int i=0; i&lt;zarray_size(detections); i++)&#123;  zarray_get(detections, i, &amp;det);  info.det = det;  apriltag_pose_t pose;  // estimate SE(3) pose   estimate_tag_pose(&amp;info, &amp;pose);  poses.push_back(pose);  ids.push_back(det-&gt;id);&#125;\nThe marker size used in our implementation corresponds to $0.162m$ (depending on the print AprilTag marker size) and the camera parameters are estimated for the wide angle lens of the Qualcomm Robotics RB5 using the OpenCV calibration tool or its ROS version and a standard checkerboard target. Notice that after you calibrate your camera and undistort the image, the undistort image will have a new camera matrix. We set the info for AprilTag to perform accurate pose estimation after getting the new camera matrix.\n1234567891011121314151617181920cv::Mat rectify(const cv::Mat image)&#123;  cv::Mat image_rect = image.clone();  // get new camera matrix after undistort  // alpha is set to 0.0 so all pixels are valid  const cv::Mat new_K = cv::getOptimalNewCameraMatrix(K, d, image.size(), 0.0);  cv::undistort(image, image_rect, K, d, new_K);  // set info for pose estimation using new camera matrix  det.setInfo(tagSize, new_K.at&lt;double&gt;(0,0), new_K.at&lt;double&gt;(1,1), new_K.at&lt;double&gt;(0,2), new_K.at&lt;double&gt;(1,2));  return image_rect;&#125;void AprilDetection::setInfo(double tagSize, double fx, double fy, double cx, double cy)&#123;  info.tagsize = tagSize;  info.fx = fx;  info.fy = fy;  info.cx = cx;  info.cy = cy;&#125;\nThe components described above have been wrapped into ROS1 and ROS2 implementations and be evaluated using the steps below. You will need to set the following parameters in the node.\n12345678910111213// TODO: Replace these parameters using your calibration resultsdouble distortion_coeff[] =        &#123;0.008549, -0.016273, -0.002954, -0.003708, 0.000000&#125;;double intrinsics[] = &#123;683.558755,    0.     ,  961.607445,                       0.     ,  680.809134,  547.701668,                       0.     ,    0.     ,    1.&#125;;const cv::Mat d(cv::Size(1, 5), CV_64FC1, distortion_coeff);const cv::Mat K(cv::Size(3, 3), CV_64FC1, intrinsics);// TODO: Set tagSize for pose estimation, assuming same tag size.// details from: https://github.com/AprilRobotics/apriltag/wiki/AprilTag-User-Guide#pose-estimationconst double tagSize = 0.162; // in meters\n\nROS1Create a workspace, clone the ROS1 implementation, and build the package. Make sure ROS is in your path, i.e. source /opt/ros/melodic/setup.bash. \n1234567891011121314# install dependencyapt install ros-melodic-apriltagmkdir -p rb5_ws/src &amp;&amp; cd rb5_ws/srcgit clone https://github.com/AutonomousVehicleLaboratory/rb5_ros.gitcd ..# build all packages in the workspacecatkin_makesource devel/setup.bash# if the build all packages failed, try build onlycatkin_make --only-pkg-with-deps rb5_visioncatkin_make --only-pkg-with-deps april_detection\n\nStart the camera node\n1roslaunch rb5_vision rb_camera_main_ocv.launch\n\nStart the AprilTag detection node\n1rosrun april_detection april_detection_node\n\n\n\nROS2Create a workspace, clone the ROS2 implementation, and build the package. Make sure ROS is in your path, i.e. source /opt/ros/dashing/setup.bash. \n12345mkdir -p rb5_ws/src &amp;&amp; cd rb5_ws/srcgit clone https://github.com/AutonomousVehicleLaboratory/rb5_ros2.gitcd ..colcon buildsource rb5_ws/install/setup.bash \n\nStart the camera node\n1ros2 launch rb5_ros2_vision rb_camera_main_ocv_launch.py\n\nStart the AprilTag detection node\n1ros2 run ros2_april_detection april_detection_node\n\n\n\nVisualizing the markers and posesFor convenience, our ROS implementations publish messages of type geometry_msgs::PoseArray (ROS1) and geometry_msgs::msg::PoseStamped (ROS2). These messages are timestamped and include a unique ID that corresponds to the marker ID as part of the message header. Nonetheless, the main component of each is message is the marker’s pose in 3D which is represented as a position (a point) and orientation (here represented as a Quaternion). While we won’t go into the math component on how Quaternions are utilized to represent orientations in 3D space, ROS has an good tools for handling transformation and can handle transformations with ease. Below is a video of each marker being visualized using the 3D visualization tool for ROS called RViz. The video demos AprilTag3 detection and real-time 3D pose estimation running onboard of Qualcomm RB5.\n\n\n\nReferences[1] AprilTag: A robust and flexible visual fiducial system\n","dateCreated":"2022-02-13T17:12:21-08:00","dateModified":"2022-10-20T16:04:35-07:00","datePublished":"2022-02-13T17:12:21-08:00","description":"","headline":"(2) April Tag Feature Detection","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"},"publisher":{"@type":"Organization","name":"RB5 ROBOTICS TUTORIALS","sameAs":[],"image":"avl-letters.png","logo":{"@type":"ImageObject","url":"avl-letters.png"}},"url":"https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/","keywords":"Feature Detection"}</script>
    <meta name="description" content="An important task in robotics is to uniquely identify features and landmarks over time as a robot navigates through the environment. The process can help estimate the robotics position (localization)">
<meta property="og:type" content="blog">
<meta property="og:title" content="(2) April Tag Feature Detection">
<meta property="og:url" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/index.html">
<meta property="og:site_name" content="RB5 ROBOTICS TUTORIALS">
<meta property="og:description" content="An important task in robotics is to uniquely identify features and landmarks over time as a robot navigates through the environment. The process can help estimate the robotics position (localization)">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/apriltags.png">
<meta property="article:published_time" content="2022-02-14T01:12:21.000Z">
<meta property="article:modified_time" content="2022-10-20T23:04:35.346Z">
<meta property="article:author" content="RB5 ROBOTICS TUTORIALS">
<meta property="article:tag" content="Feature Detection">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/apriltags.png">
    
    
        
    
    
        <meta property="og:image" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/assets/images/avl-letters.png"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/RB5_Robotics_Tutorials/assets/css/style-64qguiewfoxvxmp0xtsq6t9zwhtgymxalbr3hofnf6gpcss5mvrocwased14.min.css">

    <!--STYLES END-->
    

    

    
        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="5">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/RB5_Robotics_Tutorials/"
            aria-label=""
        >
            RB5 ROBOTICS TUTORIALS
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /RB5_Robotics_Tutorials/#about"
            >
        
        
            <img class="header-picture" src="/RB5_Robotics_Tutorials/assets/images/avl-letters.png" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="5">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/RB5_Robotics_Tutorials/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/RB5_Robotics_Tutorials/assets/images/avl-letters.png" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">RB5 ROBOTICS TUTORIALS</h4>
                
                    <h5 class="sidebar-profile-bio"><p>A set of Robotics Tutorials developed for the RB5 Robotics Development Platform from Qualcomm. Authors are from the Contextual Robotics Institute at UC San Diego.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/RB5_Robotics_Tutorials/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/RB5_Robotics_Tutorials/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/RB5_Robotics_Tutorials/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/AutonomousVehicleLaboratory"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:avl@eng.ucsd.edu"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Mail"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="5"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            (2) April Tag Feature Detection
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2022-02-13T17:12:21-08:00">
	
		    Feb 13, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/3-Robotics-Applications/">3 Robotics Applications</a>


    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>An important task in robotics is to uniquely identify features and landmarks over time as a robot navigates through the environment. The process can help estimate the robotics position (localization) to ultimately be able to perform robust path planning and navigation. In this tutorial, we will explore a popular open-source library for AprilTag detection and 3D pose estimation from a single monorcular camera. </p>
<p>AprilTags (shown in the figure below) are a form of fiducial markers that are designed with predefined sizes and patterns. The benefit of knowing their size is pose estimation given that a perspective mapping between two planes can be described by a Homography $\mathbf{H}$ matrix. In this case, $\mathbf{H}$ can describe a mapping between the camera frame and the marker since both can be assumed to be flat surfaces. This makes AprilTags an easy way of performing 3D pose estimation of objects with a single monocular camera by simply placing an AprilTag on the object. In addition, the unique pattern that defines each marker can help differentiate multiple markers that may be observable at a particular instance and by leveraging the concept of Hamming distance and dictionaries, error detection and correction can be performed in the event that part of a marker is occluded.</p>
<div class="figure " style="width:;"><img class="fig-img" src="apriltags.png" alt="Multiple AprilTag fiducial markers detected within an image with IDs 7 and 237. For marker 7, an error is detected and corrected. [1]"><span class="caption">Multiple AprilTag fiducial markers detected within an image with IDs 7 and 237. For marker 7, an error is detected and corrected. [1]</span></div>
<h2 id="The-AprilTag3-Library"><a href="#The-AprilTag3-Library" class="headerlink" title="The AprilTag3 Library"></a>The AprilTag3 Library</h2><p>Using the AprilTag library is actually quite simple and can be installed from <a target="_blank" rel="noopener" href="https://github.com/AprilRobotics/apriltag">source</a>. This includes compatible versions for C++ but also Python3. While our implementation will consist of C++, the Python version is even easier to get up and running. To install, simply run <code>pip install apriltag</code>.</p>
<p>For convenience, we have provided two implementations for AprilTag detection in ROS1 and ROS2. Given that both are C++ implementations, the logic remains the same. First, we convert our image to grayscale and populate a <code>image_u8_t</code> struct using the OpenCV <code>cv::Mat</code> image format. </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cv::Mat image_gray; </span><br><span class="line">cv::<span class="built_in">cvtColor</span>(image, image_gray, cv::COLOR_BGR2GRAY);</span><br><span class="line"></span><br><span class="line"><span class="type">image_u8_t</span> im = &#123; .width  = image_gray.cols,</span><br><span class="line">.height = image_gray.rows,</span><br><span class="line">.stride = image_gray.cols, </span><br><span class="line">.buf    = image_gray.data </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p> Once the image has been converted to grayscale, we can instantiate an <code>apriltag_detection_t</code> instance and call <code>apriltag_detector_detect()</code>. This is the primary function incharge of performing marker detection on camera data. It is worth noting that this detection object can be reused so memory can be allocated in the class constructor of your implementation.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">apriltag_detector_t</span> *a_detector = <span class="built_in">apriltag_detector_create</span>();</span><br><span class="line"><span class="type">zarray_t</span> * detections = <span class="built_in">apriltag_detector_detect</span>(a_detector, &amp;im);</span><br></pre></td></tr></table></figure>

<p>As it can be seen, <code>apriltag_detector_detect()</code> returns an array of type <code>zarray_t</code> with the list of detections concatenated. In the following code block we extract individual detections into instances of type <code>apriltag_detection_t</code> and perform a perspective mapping using the homography matrix calculated. This is handled by <code>estimate_tag_pose()</code>. However, two important considerations include <em>i)</em> that we know the size of the markers in advance, and <em>ii)</em> we understand the intrinsic parameters of the camera that include image center and focal length. These are attributes that are part of the first argument of type <code>apriltag_detection_info_t</code> that is passed to <code>estimate_tag_pose()</code>. </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">apriltag_detection_t</span> *det;</span><br><span class="line">vector&lt;<span class="type">apriltag_pose_t</span>&gt; poses;</span><br><span class="line">vector&lt;<span class="type">int</span>&gt; ids;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="built_in">zarray_size</span>(detections); i++)&#123;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">zarray_get</span>(detections, i, &amp;det);</span><br><span class="line">  info.det = det;</span><br><span class="line">  <span class="type">apriltag_pose_t</span> pose;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// estimate SE(3) pose </span></span><br><span class="line">  <span class="built_in">estimate_tag_pose</span>(&amp;info, &amp;pose);</span><br><span class="line">  poses.<span class="built_in">push_back</span>(pose);</span><br><span class="line">  ids.<span class="built_in">push_back</span>(det-&gt;id);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The marker size used in our implementation corresponds to $0.162m$ (depending on the print AprilTag marker size) and the camera parameters are estimated for the wide angle lens of the Qualcomm Robotics RB5 using the <a target="_blank" rel="noopener" href="https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html">OpenCV calibration tool</a> or its <a target="_blank" rel="noopener" href="http://wiki.ros.org/camera_calibration">ROS version</a> and a standard checkerboard target. Notice that after you calibrate your camera and undistort the image, the undistort image will have a new camera matrix. We set the info for AprilTag to perform accurate pose estimation after getting the new camera matrix.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cv::Mat <span class="title">rectify</span><span class="params">(<span class="type">const</span> cv::Mat image)</span></span>&#123;</span><br><span class="line">  cv::Mat image_rect = image.<span class="built_in">clone</span>();</span><br><span class="line">  <span class="comment">// get new camera matrix after undistort</span></span><br><span class="line">  <span class="comment">// alpha is set to 0.0 so all pixels are valid</span></span><br><span class="line">  <span class="type">const</span> cv::Mat new_K = cv::<span class="built_in">getOptimalNewCameraMatrix</span>(K, d, image.<span class="built_in">size</span>(), <span class="number">0.0</span>);</span><br><span class="line">  cv::<span class="built_in">undistort</span>(image, image_rect, K, d, new_K);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// set info for pose estimation using new camera matrix</span></span><br><span class="line">  det.<span class="built_in">setInfo</span>(tagSize, new_K.<span class="built_in">at</span>&lt;<span class="type">double</span>&gt;(<span class="number">0</span>,<span class="number">0</span>), new_K.<span class="built_in">at</span>&lt;<span class="type">double</span>&gt;(<span class="number">1</span>,<span class="number">1</span>), new_K.<span class="built_in">at</span>&lt;<span class="type">double</span>&gt;(<span class="number">0</span>,<span class="number">2</span>), new_K.<span class="built_in">at</span>&lt;<span class="type">double</span>&gt;(<span class="number">1</span>,<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> image_rect;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">AprilDetection::setInfo</span><span class="params">(<span class="type">double</span> tagSize, <span class="type">double</span> fx, <span class="type">double</span> fy, <span class="type">double</span> cx, <span class="type">double</span> cy)</span></span>&#123;</span><br><span class="line">  info.tagsize = tagSize;</span><br><span class="line">  info.fx = fx;</span><br><span class="line">  info.fy = fy;</span><br><span class="line">  info.cx = cx;</span><br><span class="line">  info.cy = cy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The components described above have been wrapped into ROS1 and ROS2 implementations and be evaluated using the steps below. You will need to set the following parameters in the node.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// <span class="doctag">TODO:</span> Replace these parameters using your calibration results</span></span><br><span class="line"><span class="type">double</span> distortion_coeff[] =</span><br><span class="line">        &#123;<span class="number">0.008549</span>, <span class="number">-0.016273</span>, <span class="number">-0.002954</span>, <span class="number">-0.003708</span>, <span class="number">0.000000</span>&#125;;</span><br><span class="line"><span class="type">double</span> intrinsics[] = &#123;<span class="number">683.558755</span>,    <span class="number">0.</span>     ,  <span class="number">961.607445</span>,</span><br><span class="line">                       <span class="number">0.</span>     ,  <span class="number">680.809134</span>,  <span class="number">547.701668</span>,</span><br><span class="line">                       <span class="number">0.</span>     ,    <span class="number">0.</span>     ,    <span class="number">1.</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">const</span> cv::Mat <span class="title">d</span><span class="params">(cv::Size(<span class="number">1</span>, <span class="number">5</span>), CV_64FC1, distortion_coeff)</span></span>;</span><br><span class="line"><span class="function"><span class="type">const</span> cv::Mat <span class="title">K</span><span class="params">(cv::Size(<span class="number">3</span>, <span class="number">3</span>), CV_64FC1, intrinsics)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// <span class="doctag">TODO:</span> Set tagSize for pose estimation, assuming same tag size.</span></span><br><span class="line"><span class="comment">// details from: https://github.com/AprilRobotics/apriltag/wiki/AprilTag-User-Guide#pose-estimation</span></span><br><span class="line"><span class="type">const</span> <span class="type">double</span> tagSize = <span class="number">0.162</span>; <span class="comment">// in meters</span></span><br></pre></td></tr></table></figure>

<h2 id="ROS1"><a href="#ROS1" class="headerlink" title="ROS1"></a>ROS1</h2><p>Create a workspace, clone the ROS1 implementation, and build the package. Make sure ROS is in your path, i.e. <code>source /opt/ros/melodic/setup.bash</code>. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># install dependency</span><br><span class="line">apt install ros-melodic-apriltag</span><br><span class="line"></span><br><span class="line">mkdir -p rb5_ws/src &amp;&amp; cd rb5_ws/src</span><br><span class="line">git clone https://github.com/AutonomousVehicleLaboratory/rb5_ros.git</span><br><span class="line">cd ..</span><br><span class="line"></span><br><span class="line"># build all packages in the workspace</span><br><span class="line">catkin_make</span><br><span class="line">source devel/setup.bash</span><br><span class="line"></span><br><span class="line"># if the build all packages failed, try build only</span><br><span class="line">catkin_make --only-pkg-with-deps rb5_vision</span><br><span class="line">catkin_make --only-pkg-with-deps april_detection</span><br></pre></td></tr></table></figure>

<p>Start the camera node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">roslaunch rb5_vision rb_camera_main_ocv.launch</span><br></pre></td></tr></table></figure>

<p>Start the AprilTag detection node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rosrun april_detection april_detection_node</span><br></pre></td></tr></table></figure>



<h2 id="ROS2"><a href="#ROS2" class="headerlink" title="ROS2"></a>ROS2</h2><p>Create a workspace, clone the ROS2 implementation, and build the package. Make sure ROS is in your path, i.e. <code>source /opt/ros/dashing/setup.bash</code>. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p rb5_ws/src &amp;&amp; cd rb5_ws/src</span><br><span class="line">git clone https://github.com/AutonomousVehicleLaboratory/rb5_ros2.git</span><br><span class="line">cd ..</span><br><span class="line">colcon build</span><br><span class="line">source rb5_ws/install/setup.bash </span><br></pre></td></tr></table></figure>

<p>Start the camera node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ros2 launch rb5_ros2_vision rb_camera_main_ocv_launch.py</span><br></pre></td></tr></table></figure>

<p>Start the AprilTag detection node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ros2 run ros2_april_detection april_detection_node</span><br></pre></td></tr></table></figure>



<h2 id="Visualizing-the-markers-and-poses"><a href="#Visualizing-the-markers-and-poses" class="headerlink" title="Visualizing the markers and poses"></a>Visualizing the markers and poses</h2><p>For convenience, our ROS implementations publish messages of type <code>geometry_msgs::PoseArray</code> (<a target="_blank" rel="noopener" href="http://docs.ros.org/en/melodic/api/geometry_msgs/html/msg/PoseArray.html">ROS1</a>) and <code>geometry_msgs::msg::PoseStamped</code> (<a target="_blank" rel="noopener" href="https://docs.ros2.org/foxy/api/geometry_msgs/msg/PoseStamped.html">ROS2</a>). These messages are timestamped and include a unique ID that corresponds to the marker ID as part of the message header. Nonetheless, the main component of each is message is the marker’s pose in 3D which is represented as a position (a point) and orientation (here represented as a Quaternion). While we won’t go into the math component on how Quaternions are utilized to represent orientations in 3D space, ROS has an good tools for handling transformation and can handle transformations with ease. Below is a video of each marker being visualized using the 3D visualization tool for ROS called RViz. The video demos AprilTag3 detection and real-time 3D pose estimation running onboard of Qualcomm RB5.</p>
<div class="video-container"><iframe src="https://www.youtube.com/embed/qRoW6ljBfFo" frameborder="0" loading="lazy" allowfullscreen></iframe></div>


<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a target="_blank" rel="noopener" href="https://april.eecs.umich.edu/media/pdfs/olson2011tags.pdf">AprilTag: A robust and flexible visual fiducial system</a></p>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/RB5_Robotics_Tutorials/tags/Feature-Detection/" rel="tag">Feature Detection</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/RB5_Robotics_Tutorials/2022/02/13/1%20Initial%20Set-up/bring-up-rb5/"
                    data-tooltip="(1) Bring Up Qualcomm Robotics RB5"
                    aria-label="PREVIOUS: (1) Bring Up Qualcomm Robotics RB5"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    <a
                        class="post-action-btn btn btn--disabled"
                        aria-hidden="true"
                    >
                        
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2022 RB5 ROBOTICS TUTORIALS. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/RB5_Robotics_Tutorials/2022/02/13/1%20Initial%20Set-up/bring-up-rb5/"
                    data-tooltip="(1) Bring Up Qualcomm Robotics RB5"
                    aria-label="PREVIOUS: (1) Bring Up Qualcomm Robotics RB5"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    <a
                        class="post-action-btn btn btn--disabled"
                        aria-hidden="true"
                    >
                        
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="5">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://plus.google.com/share?url=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                        aria-label="Share on Google+"
                    >
                        <i class="fab fa-google-plus" aria-hidden="true"></i><span>Share on Google+</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/RB5_Robotics_Tutorials/assets/images/avl-letters.png" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">RB5 ROBOTICS TUTORIALS</h4>
        
            <div id="about-card-bio"><p>A set of Robotics Tutorials developed for the RB5 Robotics Development Platform from Qualcomm. Authors are from the Contextual Robotics Institute at UC San Diego.</p>
</div>
        
        
            <div id="about-card-bio">
                <p>Contributors</p>

                <!-- <i class="fa fa-briefcase"></i>
                <br/> -->
                <p>Henrik I. Christensen, David Paz, Henry Zhang, Anirudh Ramesh.</p>

            </div>
        
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/RB5_Robotics_Tutorials/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/RB5_Robotics_Tutorials/assets/js/script-ouavugrvd9qj6lg3dktmularsze8hx0ahydxl4n9zvn5qystucng5rouil06.min.js"></script>

<!--SCRIPTS END-->


    




    </body>
</html>
