
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="RB5 ROBOTICS TUTORIALS">
    <title>(1) Running DeepLabV3 Model - RB5 ROBOTICS TUTORIALS</title>
    <meta name="author" content="RB5 ROBOTICS TUTORIALS">
    
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"RB5 ROBOTICS TUTORIALS","sameAs":[],"image":"avl-letters.png"},"articleBody":"This tutorial explains the process of setting up the SNPE SDK and running inference on RB5 using a TensorFlow and PyTorch segmentation model. \nNote: This can be extended to any Deep Learning models\nTesnorFlowRunning Inference on Ubuntu 18.0.4:This section will guide you in setting up the SNPE on a Ubuntu system and running inference using the TensorFlow model for DeepLabV3\n\nDownload pre-trained DeepLabV3 model trained using TensorFlow:\n\n12wget http://download.tensorflow.org/modelsdeeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gztar -xzvf deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz\n\n\nSetup Qualcomm Snapdragon Neural Processing Engine SDK on the system using the tutorial mentioned below.\n\n12sudo snap install --classic android-studio #Android Studio installation is necessary for SNPE SDK to workhttps://developer.qualcomm.com/software/qualcomm-neural-processing-sdk/getting-started\nNote: Make sure all the path variables are set properly according to the tutorial provided in the above links. Failing to set the paths will result in the following command to fail.\n\nSet the environment path for TensorFlow\n\n123cd $SNPE_ROOTexport TENSORFLOW_DIR=&quot;your_tensorflow_installation_dir&quot;source bin/envsetup.sh -o $TENSORFLOW_DIR\n\n\n\nConvert the model to .dlc format using the following command\n\n1snpe-tensorflow-to-dlc --input_dim sub_7 1,513,513,3 --out_node ArgMax --input_network ./deeplabv3_mnv2_pascal_train_aug/frozen_inference_graph.pb\nNote: The “.&#x2F;deeplabv3_mnv2_pascal_train_aug&#x2F;frozen_inference_graph.pb” is the downloaded TF model and the image size is set to 513x513x3 as an example\n\nRunning Inference:\n\n\nPreprocess the image using the Python script below. Example image is provided.\n123456789101112131415import numpy as npimport cv2from matplotlib import pyplot as pltframe = cv2.imread(&#x27;Example.jpeg&#x27;)# Resize frame with Required image sizeframe_resized = cv2.resize(frame,(513,513))# Pad smaller dimensions to Mean value &amp; Multiply with 0.007843blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (513, 513), (127.5, 127.5, 127.5), swapRB=True)# Making numpy array of required shapeblob = np.reshape(blob, (1,513,513,3))# Storing to a raw filenp.ndarray.tofile(blob, open(&#x27;blob.raw&#x27;,&#x27;w&#x27;) )\n\nPrepare a text file that contains all the images you would like to run inference on\n\nCreate a file names “raw_list.txt” in the current directory\nEnter the path of the “blob.raw” file that was generated using the Python script\n\n\nRun the following command to use the generated dlc model to run inference\n\n\n1snpe-net-run --container deeplabv3.dlc --input_list ./raw_list.txt\nThis command generates a file called “ArgMax:0.raw” in “&#x2F;output&#x2F;Result_0&#x2F;” path that will be used as an input to out model.\n\nRun the input below Python script to obtain the segmentation masks and modify the image\n\n12345678910111213141516171819import cv2import numpy as npfrom matplotlib import pyplot as pltarr = np.fromfile(open(&#x27;ArgMax:0.raw&#x27;, &#x27;r&#x27;), dtype=&quot;float32&quot;)arr = np.reshape(arr, (513,513,1))segment = arr[342:, 342:]arr[arr == 15] = 255original_img = cv2.imread(&#x27;deeplab-check.jpeg&#x27;)arr2=cv2.resize(segment,(original_img.shape[1], original_img.shape[0]))print(arr.shape)for i in range(arr2.shape[0]):    for j in range(arr2.shape[1]):        if (arr2[i][j] != 255):            original_img[i][j] = original_img[i][j][0] = original_img[i][j][1] = original_img[i][j][2]plt.imshow(original_img)plt.show()plt.imshow( arr, cmap=&quot;gray&quot;)plt.show()\n\nRunning Inference on RB5:The SNPE SDK provides binaries for RB5’s architecture. To check out the list of supported architectures, run\nOn Ubuntu:12cd $SNPE_ROOT/lib #Ensure the path export from SNPE installationls\n\nFor the Qualcomm RB5 platform, we are interested in in the following folders:\n\naarch64-ubuntu-gcc7.5\ndsp\n\nThese folders need to be copied over to the RB5 either by using “adb shell”, “adb push” or “scp” commands.\n\nSelect the architecture aarch64-ubuntu-gcc7.5\n\n1export SNPE_TARGET_ARCH=aarch64-ubuntu-gcc7.5\n\n\nPush the binaries to target\n\n12345adb shell &quot;mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin&quot; # Creates a folder with the architecture&#x27;s nameadb shell &quot;mkdir -p /data/local/tmp/snpeexample/dsp/lib&quot; #Creates lib folder to copy over the libraries toadb push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib #Copy the architecture librariesadb push $SNPE_ROOT/lib/dsp/*.so  /data/local/tmp/snpeexample/dsp/libadb push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n\nOnce the libraries are copied over, log into RB5 using “adb shell” command or use a monitor(preferred as the final result involves visualizing)\nOn RB5:\nSet tup the target architecture, library path and environment variables for “snpe-net-run” command to run successfully\n\n123export SNPE_TARGET_ARCH=aarch64-ubuntu-gcc7.5export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/libexport PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n\nNote: These commands need to be run everytime a new terminal is opened. To avoid this, add these commands in ~&#x2F;.bashrc file and run “source ~&#x2F;.bashrc”\n\nVerify snpe-net-run copy\n\n1snpe-net-run -h #This command should run successfully and list the available options\n\n\nCopy the Python scripts and the “.dlc” file and the images from “Running Inference on Ubuntu 18.0.4” section to run inference\n\nFollow Step 4 from the previous section to run inference. (Feel free to skip the blob.raw generation if it is already copied over)\n\n\nNote: The inference step involves running “snpe-net-run”.\nNote: Once the masks are obtained, it can be used for any application. We have shown a simple background blur in this example.\nPyTorchA PyTorch model can be converted to dlc format to be run on RB5 as mentioned in the following sections. \nImportant: PyTorch models need to be converted to ONNX before they are converted to dlc format.\n\nRun the following script to generate DeepLabV3 ONNX model. Here we use pre-trained DeepLabV3 model available in TorchHub\n\n123456789101112131415import torchimport torchvisionBEST_MODEL_PATH_ONNX = &quot;deeplabv3_onnx_model.onnx&quot;#Load pre-trained Modelmodel = torch.hub.load(&#x27;pytorch/vision:v0.7.0&#x27;, &#x27;deeplabv3_resnet50&#x27;, pretrained=True)model.eval()x = torch.randn(1, 3, 224, 224, requires_grad=True)y = model(x)torch_out = torch.onnx._export(model,                   # model being run                                x,                      # model input (or a tuple for multiple inputs)                                BEST_MODEL_PATH_ONNX,   # where to save the model (can be a file or file-like object)                                export_params=True,     # store the trained parameter weights inside the model file                                input_names=[&#x27;Conv2d0_3-64&#x27;],     # specify the name of input layer in onnx model                                output_names=[&#x27;Linear2_4096-2&#x27;])    # specify the name of output layerprint(&quot;Successfully genereated ONNX model at &quot;,BEST_MODEL_PATH_ONNX)\n\n\nInstall ONNX on Ubuntu system\n\n1pip install onnx\n\n\nSet the environment path for ONNX\n\n123cd $SNPE_ROOTexport ONNX_DIR=&quot;your_onnx_installation_dir&quot;source bin/envsetup.sh -o $ONNX_DIR\n\n\nRun ONNX to DLC conversion command\n\n1snpe-onnx-to-dlc --input_dim sub_7 1,513,513,3 --out_node ArgMax --input_network /deeplabv3_onnx_model.onnx --output_path deeplab_pt.dlc\n\n\nOnce the dlc format is generated successfully, follow the “Running Inference” sections in TensorFlow section to run inference on both Ubuntu and RB5\n\nExample Input Image\n\nGenerated Mask\n\nPost Processed Image\n\n","dateCreated":"2022-05-18T17:12:21-07:00","dateModified":"2022-05-22T12:03:06-07:00","datePublished":"2022-05-18T17:12:21-07:00","description":"","headline":"(1) Running DeepLabV3 Model","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"},"publisher":{"@type":"Organization","name":"RB5 ROBOTICS TUTORIALS","sameAs":[],"image":"avl-letters.png","logo":{"@type":"ImageObject","url":"avl-letters.png"}},"url":"https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/","keywords":"Deep Learning"}</script>
    <meta name="description" content="This tutorial explains the process of setting up the SNPE SDK and running inference on RB5 using a TensorFlow and PyTorch segmentation model.  Note: This can be extended to any Deep Learning models Te">
<meta property="og:type" content="blog">
<meta property="og:title" content="(1) Running DeepLabV3 Model">
<meta property="og:url" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/index.html">
<meta property="og:site_name" content="RB5 ROBOTICS TUTORIALS">
<meta property="og:description" content="This tutorial explains the process of setting up the SNPE SDK and running inference on RB5 using a TensorFlow and PyTorch segmentation model.  Note: This can be extended to any Deep Learning models Te">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/Example.png">
<meta property="og:image" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/Mask.png">
<meta property="og:image" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/PostProcessed.png">
<meta property="article:published_time" content="2022-05-19T00:12:21.000Z">
<meta property="article:modified_time" content="2022-05-22T19:03:06.394Z">
<meta property="article:author" content="RB5 ROBOTICS TUTORIALS">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/Example.png">
    
    
        
    
    
        <meta property="og:image" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/assets/images/avl-letters.png"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/RB5_Robotics_Tutorials/assets/css/style-64qguiewfoxvxmp0xtsq6t9zwhtgymxalbr3hofnf6gpcss5mvrocwased14.min.css">

    <!--STYLES END-->
    

    

    
        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="5">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/RB5_Robotics_Tutorials/"
            aria-label=""
        >
            RB5 ROBOTICS TUTORIALS
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /RB5_Robotics_Tutorials/#about"
            >
        
        
            <img class="header-picture" src="/RB5_Robotics_Tutorials/assets/images/avl-letters.png" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="5">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/RB5_Robotics_Tutorials/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/RB5_Robotics_Tutorials/assets/images/avl-letters.png" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">RB5 ROBOTICS TUTORIALS</h4>
                
                    <h5 class="sidebar-profile-bio"><p>A set of Robotics Tutorials developed for the RB5 Robotics Development Platform from Qualcomm. Authors are from the Contextual Robotics Institute at UC San Diego.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/RB5_Robotics_Tutorials/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/RB5_Robotics_Tutorials/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/RB5_Robotics_Tutorials/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/AutonomousVehicleLaboratory"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:avl@eng.ucsd.edu"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Mail"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="5"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            (1) Running DeepLabV3 Model
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2022-05-18T17:12:21-07:00">
	
		    May 18, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/4-ML-at-the-Edge/">4 ML at the Edge</a>


    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>This tutorial explains the process of setting up the SNPE SDK and running inference on RB5 using a TensorFlow and PyTorch segmentation model. </p>
<p>Note: This can be extended to any Deep Learning models</p>
<h2 id="TesnorFlow"><a href="#TesnorFlow" class="headerlink" title="TesnorFlow"></a>TesnorFlow</h2><h3 id="Running-Inference-on-Ubuntu-18-0-4"><a href="#Running-Inference-on-Ubuntu-18-0-4" class="headerlink" title="Running Inference on Ubuntu 18.0.4:"></a>Running Inference on Ubuntu 18.0.4:</h3><p>This section will guide you in setting up the SNPE on a Ubuntu system and running inference using the TensorFlow model for DeepLabV3</p>
<ol>
<li>Download pre-trained DeepLabV3 model trained using TensorFlow:</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.tensorflow.org/modelsdeeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz</span><br><span class="line">tar -xzvf deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Setup Qualcomm Snapdragon Neural Processing Engine SDK on the system using the tutorial mentioned below.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo snap install --classic android-studio #Android Studio installation is necessary for SNPE SDK to work</span><br><span class="line">https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk/getting-started</span><br></pre></td></tr></table></figure>
<p>Note: Make sure all the path variables are set properly according to the tutorial provided in the above links. Failing to set the paths will result in the following command to fail.</p>
<ol start="3">
<li>Set the environment path for TensorFlow</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd $SNPE_ROOT</span><br><span class="line">export TENSORFLOW_DIR=&quot;your_tensorflow_installation_dir&quot;</span><br><span class="line">source bin/envsetup.sh -o $TENSORFLOW_DIR</span><br></pre></td></tr></table></figure>


<ol start="4">
<li>Convert the model to .dlc format using the following command</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snpe-tensorflow-to-dlc --input_dim sub_7 1,513,513,3 --out_node ArgMax --input_network ./deeplabv3_mnv2_pascal_train_aug/frozen_inference_graph.pb</span><br></pre></td></tr></table></figure>
<p>Note: The “.&#x2F;deeplabv3_mnv2_pascal_train_aug&#x2F;frozen_inference_graph.pb” is the downloaded TF model and the image size is set to 513x513x3 as an example</p>
<ol start="5">
<li>Running Inference:</li>
</ol>
<ul>
<li><p>Preprocess the image using the Python script below. Example image is provided.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line">frame = cv2.imread(&#x27;Example.jpeg&#x27;)</span><br><span class="line"># Resize frame with Required image size</span><br><span class="line">frame_resized = cv2.resize(frame,(513,513))</span><br><span class="line"># Pad smaller dimensions to Mean value &amp; Multiply with 0.007843</span><br><span class="line">blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (513, 513), (127.5, 127.5, 127.5), swapRB=True)</span><br><span class="line"></span><br><span class="line"># Making numpy array of required shape</span><br><span class="line">blob = np.reshape(blob, (1,513,513,3))</span><br><span class="line"></span><br><span class="line"># Storing to a raw file</span><br><span class="line">np.ndarray.tofile(blob, open(&#x27;blob.raw&#x27;,&#x27;w&#x27;) )</span><br></pre></td></tr></table></figure>
</li>
<li><p>Prepare a text file that contains all the images you would like to run inference on</p>
<ul>
<li>Create a file names “raw_list.txt” in the current directory</li>
<li>Enter the path of the “blob.raw” file that was generated using the Python script</li>
</ul>
</li>
<li><p>Run the following command to use the generated dlc model to run inference</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snpe-net-run --container deeplabv3.dlc --input_list ./raw_list.txt</span><br></pre></td></tr></table></figure>
<p>This command generates a file called “ArgMax:0.raw” in “&#x2F;output&#x2F;Result_0&#x2F;” path that will be used as an input to out model.</p>
<ul>
<li>Run the input below Python script to obtain the segmentation masks and modify the image</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line">arr = np.fromfile(open(&#x27;ArgMax:0.raw&#x27;, &#x27;r&#x27;), dtype=&quot;float32&quot;)</span><br><span class="line">arr = np.reshape(arr, (513,513,1))</span><br><span class="line">segment = arr[342:, 342:]</span><br><span class="line">arr[arr == 15] = 255</span><br><span class="line">original_img = cv2.imread(&#x27;deeplab-check.jpeg&#x27;)</span><br><span class="line">arr2=cv2.resize(segment,(original_img.shape[1], original_img.shape[0]))</span><br><span class="line">print(arr.shape)</span><br><span class="line">for i in range(arr2.shape[0]):</span><br><span class="line">    for j in range(arr2.shape[1]):</span><br><span class="line">        if (arr2[i][j] != 255):</span><br><span class="line">            original_img[i][j] = original_img[i][j][0] = original_img[i][j][1] = original_img[i][j][2]</span><br><span class="line">plt.imshow(original_img)</span><br><span class="line">plt.show()</span><br><span class="line">plt.imshow( arr, cmap=&quot;gray&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="Running-Inference-on-RB5"><a href="#Running-Inference-on-RB5" class="headerlink" title="Running Inference on RB5:"></a>Running Inference on RB5:</h3><p>The SNPE SDK provides binaries for RB5’s architecture. To check out the list of supported architectures, run</p>
<h4 id="On-Ubuntu"><a href="#On-Ubuntu" class="headerlink" title="On Ubuntu:"></a>On Ubuntu:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $SNPE_ROOT/lib #Ensure the path export from SNPE installation</span><br><span class="line">ls</span><br></pre></td></tr></table></figure>

<p>For the Qualcomm RB5 platform, we are interested in in the following folders:</p>
<ul>
<li>aarch64-ubuntu-gcc7.5</li>
<li>dsp</li>
</ul>
<p>These folders need to be copied over to the RB5 either by using “adb shell”, “adb push” or “scp” commands.</p>
<ol>
<li>Select the architecture aarch64-ubuntu-gcc7.5</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export SNPE_TARGET_ARCH=aarch64-ubuntu-gcc7.5</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Push the binaries to target</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">adb shell &quot;mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin&quot; # Creates a folder with the architecture&#x27;s name</span><br><span class="line">adb shell &quot;mkdir -p /data/local/tmp/snpeexample/dsp/lib&quot; #Creates lib folder to copy over the libraries to</span><br><span class="line">adb push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib #Copy the architecture libraries</span><br><span class="line">adb push $SNPE_ROOT/lib/dsp/*.so  /data/local/tmp/snpeexample/dsp/lib</span><br><span class="line">adb push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin</span><br></pre></td></tr></table></figure>

<p>Once the libraries are copied over, log into RB5 using “adb shell” command or use a monitor(preferred as the final result involves visualizing)</p>
<h4 id="On-RB5"><a href="#On-RB5" class="headerlink" title="On RB5:"></a>On RB5:</h4><ol>
<li>Set tup the target architecture, library path and environment variables for “snpe-net-run” command to run successfully</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export SNPE_TARGET_ARCH=aarch64-ubuntu-gcc7.5</span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib</span><br><span class="line">export PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin</span><br></pre></td></tr></table></figure>

<p>Note: These commands need to be run everytime a new terminal is opened. To avoid this, add these commands in ~&#x2F;.bashrc file and run “source ~&#x2F;.bashrc”</p>
<ol start="2">
<li>Verify snpe-net-run copy</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snpe-net-run -h #This command should run successfully and list the available options</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>Copy the Python scripts and the “.dlc” file and the images from “Running Inference on Ubuntu 18.0.4” section to run inference</p>
</li>
<li><p>Follow Step 4 from the previous section to run inference. (Feel free to skip the blob.raw generation if it is already copied over)</p>
</li>
</ol>
<p>Note: The inference step involves running “snpe-net-run”.</p>
<p>Note: Once the masks are obtained, it can be used for any application. We have shown a simple background blur in this example.</p>
<h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><p>A PyTorch model can be converted to dlc format to be run on RB5 as mentioned in the following sections. </p>
<p>Important: PyTorch models need to be converted to ONNX before they are converted to dlc format.</p>
<ol>
<li>Run the following script to generate DeepLabV3 ONNX model. Here we use pre-trained DeepLabV3 model available in TorchHub</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">BEST_MODEL_PATH_ONNX = &quot;deeplabv3_onnx_model.onnx&quot;</span><br><span class="line">#Load pre-trained Model</span><br><span class="line">model = torch.hub.load(&#x27;pytorch/vision:v0.7.0&#x27;, &#x27;deeplabv3_resnet50&#x27;, pretrained=True)</span><br><span class="line">model.eval()</span><br><span class="line">x = torch.randn(1, 3, 224, 224, requires_grad=True)</span><br><span class="line">y = model(x)</span><br><span class="line">torch_out = torch.onnx._export(model,                   # model being run</span><br><span class="line">                                x,                      # model input (or a tuple for multiple inputs)</span><br><span class="line">                                BEST_MODEL_PATH_ONNX,   # where to save the model (can be a file or file-like object)</span><br><span class="line">                                export_params=True,     # store the trained parameter weights inside the model file</span><br><span class="line">                                input_names=[&#x27;Conv2d0_3-64&#x27;],     # specify the name of input layer in onnx model</span><br><span class="line">                                output_names=[&#x27;Linear2_4096-2&#x27;])    # specify the name of output layer</span><br><span class="line">print(&quot;Successfully genereated ONNX model at &quot;,BEST_MODEL_PATH_ONNX)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Install ONNX on Ubuntu system</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install onnx</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Set the environment path for ONNX</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd $SNPE_ROOT</span><br><span class="line">export ONNX_DIR=&quot;your_onnx_installation_dir&quot;</span><br><span class="line">source bin/envsetup.sh -o $ONNX_DIR</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>Run ONNX to DLC conversion command</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snpe-onnx-to-dlc --input_dim sub_7 1,513,513,3 --out_node ArgMax --input_network /deeplabv3_onnx_model.onnx --output_path deeplab_pt.dlc</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>Once the dlc format is generated successfully, follow the “Running Inference” sections in TensorFlow section to run inference on both Ubuntu and RB5</li>
</ol>
<div class="figure " style="width:;"><img class="fig-img" src="Example.png" alt="Example Input Image"><span class="caption">Example Input Image</span></div>

<div class="figure " style="width:;"><img class="fig-img" src="Mask.png" alt="Generated Mask"><span class="caption">Generated Mask</span></div>

<div class="figure " style="width:;"><img class="fig-img" src="PostProcessed.png" alt="Post Processed Image"><span class="caption">Post Processed Image</span></div>


            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/RB5_Robotics_Tutorials/tags/Deep-Learning/" rel="tag">Deep Learning</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/RB5_Robotics_Tutorials/2022/05/18/3%20Robotics%20Applications/setup-orb-slam3-on-rb5/"
                    data-tooltip="(3) Setup ORB_SLAM3 on RB5"
                    aria-label="PREVIOUS: (3) Setup ORB_SLAM3 on RB5"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/RB5_Robotics_Tutorials/2022/02/15/2%20Accessing%20Devices/accessing-camera-on-rb5/"
                    data-tooltip="(1) Accessing Camera on RB5"
                    aria-label="NEXT: (1) Accessing Camera on RB5"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2022 RB5 ROBOTICS TUTORIALS. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/RB5_Robotics_Tutorials/2022/05/18/3%20Robotics%20Applications/setup-orb-slam3-on-rb5/"
                    data-tooltip="(3) Setup ORB_SLAM3 on RB5"
                    aria-label="PREVIOUS: (3) Setup ORB_SLAM3 on RB5"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/RB5_Robotics_Tutorials/2022/02/15/2%20Accessing%20Devices/accessing-camera-on-rb5/"
                    data-tooltip="(1) Accessing Camera on RB5"
                    aria-label="NEXT: (1) Accessing Camera on RB5"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="5">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://plus.google.com/share?url=https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                        aria-label="Share on Google+"
                    >
                        <i class="fab fa-google-plus" aria-hidden="true"></i><span>Share on Google+</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/RB5_Robotics_Tutorials/assets/images/avl-letters.png" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">RB5 ROBOTICS TUTORIALS</h4>
        
            <div id="about-card-bio"><p>A set of Robotics Tutorials developed for the RB5 Robotics Development Platform from Qualcomm. Authors are from the Contextual Robotics Institute at UC San Diego.</p>
</div>
        
        
            <div id="about-card-bio">
                <p>Contributors</p>

                <!-- <i class="fa fa-briefcase"></i>
                <br/> -->
                <p>Henrik I. Christensen, David Paz, Henry Zhang, Anirudh Ramesh.</p>

            </div>
        
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/RB5_Robotics_Tutorials/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/RB5_Robotics_Tutorials/assets/js/script-ouavugrvd9qj6lg3dktmularsze8hx0ahydxl4n9zvn5qystucng5rouil06.min.js"></script>

<!--SCRIPTS END-->


    




    </body>
</html>
