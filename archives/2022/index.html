
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="RB5 ROBOTICS TUTORIALS">
    <title>Archives: 2022 - RB5 ROBOTICS TUTORIALS</title>
    <meta name="author" content="RB5 ROBOTICS TUTORIALS">
    
    
    
    <script type="application/ld+json">{}</script>
    <meta name="description" content="Some description for subtitle">
<meta property="og:type" content="blog">
<meta property="og:title" content="RB5 ROBOTICS TUTORIALS">
<meta property="og:url" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/archives/2022/index.html">
<meta property="og:site_name" content="RB5 ROBOTICS TUTORIALS">
<meta property="og:description" content="Some description for subtitle">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="RB5 ROBOTICS TUTORIALS">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/assets/images/avl-letters.png"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/RB5_Robotics_Tutorials/assets/css/style-64qguiewfoxvxmp0xtsq6t9zwhtgymxalbr3hofnf6gpcss5mvrocwased14.min.css">

    <!--STYLES END-->
    

    

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="2">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/RB5_Robotics_Tutorials/"
            aria-label=""
        >
            RB5 ROBOTICS TUTORIALS
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /RB5_Robotics_Tutorials/#about"
            >
        
        
            <img class="header-picture" src="/RB5_Robotics_Tutorials/assets/images/avl-letters.png" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="2">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/RB5_Robotics_Tutorials/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/RB5_Robotics_Tutorials/assets/images/avl-letters.png" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">RB5 ROBOTICS TUTORIALS</h4>
                
                    <h5 class="sidebar-profile-bio"><p>A set of Robotics Tutorials developed for the RB5 Robotics Development Platform from Qualcomm. Authors are from the Contextual Robotics Institute at UC San Diego.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/RB5_Robotics_Tutorials/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/RB5_Robotics_Tutorials/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/RB5_Robotics_Tutorials/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/AutonomousVehicleLaboratory"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:avl@eng.ucsd.edu"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Mail"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="2"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/RB5_Robotics_Tutorials/2022/05/22/3%20Robotics%20Applications/control-example-interface/"
                            aria-label=": (4) Control - An example interface using the Megabot Robot"
                        >
                            (4) Control - An example interface using the Megabot Robot
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2022-05-22T17:12:21-07:00">
	
		    May 22, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/3-Robotics-Applications/">3 Robotics Applications</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>As we describe in our previous tutorial on <a href="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/05/18/2%20Accessing%20Devices/building-and-loading-kernel-modules/">building and loading kernel modules on the RB5</a>, the Ubuntu 18.04 installation that is part of the RB5 LU build includes minimal package support to reduce OS complexity. With this in mind, if we wish to install custom drivers, we need to perform the process described. Thankfully, if you have build and loaded the kernel modules described in our tutorial, you will be able to interface with a standard joystick controller over USB and serial over USB.</p>
<p>With the preliminaries completed, we will use the <a target="_blank" rel="noopener" href="https://store.makeblock.com/products/makeblock-mbot-mega-robot-kit">Megabot Robot</a> as an example to interface with an RB5. In this case, we will use the <code>megapi</code> Python module designed for the Megabot to communite with the robot. This can be readily installed using <code>pip install megapi</code>.</p>
<p>Here we define a set of primitive actions that can control this four-mechanum-wheel robot. The set of primitive control actions include move <code>left</code>,<code>right</code>,<code>forward</code>, <code>in reverse</code>, rotate <code>clockwise</code>, <code>counter-clockwise</code>, and <code>stop</code>. Yes, it come as a surprise to many but the wheels on the robot contain a number of different rollers that ultimately influence the kinematics of the robot and jointly provide very interesting properties such as rotating in place and moving sideways!</p>
<p>The inverse kinematics of the robot can be described below.</p>
 <img src="./control-example/inverse.png" align="center" />



<p>For example, if we wish to make the robot move left without rotating (defining our reference frame as $+y$ (left) and $+x$ (up)), $v_x&#x3D;0$ and $v_y&#x3D;v$, this implies $[\omega_1, \omega_2, \omega_3, \omega_4]^\intercal &#x3D; [-v, v, v, -v]^\intercal$</p>
<h2 id="ROS1"><a href="#ROS1" class="headerlink" title="ROS1"></a>ROS1</h2><p>Create a workspace, clone the ROS1 implementation, and build the package. Make sure ROS is in your path, i.e. <code>source /opt/ros/melodic/setup.bash</code>. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p rb5_ws/src &amp;&amp; cd rb5_ws/src</span><br><span class="line">git clone https://github.com/AutonomousVehicleLaboratory/rb5_ros.git</span><br><span class="line">cd ..</span><br><span class="line">catkin_make</span><br><span class="line">source rb5_ws/devel/setup.bash </span><br></pre></td></tr></table></figure>

<p>Start the control node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ros run rb5_control rb5_mpi_control.py</span><br></pre></td></tr></table></figure>



<h2 id="ROS2"><a href="#ROS2" class="headerlink" title="ROS2"></a>ROS2</h2><p>Create a workspace, clone the ROS2 implementation, and build the package. Make sure ROS is in your path, i.e. <code>source /opt/ros/dashing/setup.bash</code>. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p rb5_ws/src &amp;&amp; cd rb5_ws/src</span><br><span class="line">git clone https://github.com/AutonomousVehicleLaboratory/rb5_ros2.git</span><br><span class="line">cd ..</span><br><span class="line">colcon build</span><br><span class="line">source rb5_ws/install/setup.bash </span><br></pre></td></tr></table></figure>

<p>Start the control node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ros2 run rb5_ros2_control rb5_mpi_control.py</span><br></pre></td></tr></table></figure>






<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3>
                    
                        


                    
                    
                        <p>
                            <a
                                href="/RB5_Robotics_Tutorials/2022/05/22/3%20Robotics%20Applications/control-example-interface/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/RB5_Robotics_Tutorials/2022/05/21/3%20Robotics%20Applications/ros-installation/"
                            aria-label=": (1) ROS Installation"
                        >
                            (1) ROS Installation
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2022-05-21T17:12:21-07:00">
	
		    May 21, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/3-Robotics-Applications/">3 Robotics Applications</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>This tutorial outlines the process of installing ROS which is short for Robot Operating System. While ROS is not an operating system in the traditional sense, this is an ecosystem that provides support for a wide variety of sensor drivers and software libraries to aid in the fast development of robotic applications. Whether it is to process camera data or to execute a motion plan to reach a target destination, ROS handles message passing between modules to enable communication across multiple software modules. </p>
<p>In the following two subsections, we outline the installation process of two ROS versions, namely ROS1 (Melodic) and ROS2 (Dashing) that were specifically designed to run on native Ubuntu 18.04 systems. As the naming system suggests, ROS1 precedes ROS2; however, each can come with newer&#x2F;older flavors for each (i.e. Kinetic, Melodic, Neotic are ROS1 versions and Dashing, Foxy, and Galactic are ROS2 flavors). While the operating system support varies across releases, the key differences between ROS1 and ROS2 involve package support and features. </p>
<p>As far as benefits, a key benefit of using ROS2 involves security, stability, and its focus on making it compatible with industrial robotic applications that require reliability. However, some may find that open source packages that were previously availble in ROS1 are not entirely ported to ROS2. This is quickly changing but it is a tradeoff to consider during development.</p>
<p>In future tutorials, we will explore applications that utilize Melodic and Dashing as the basis for our applications since they are Ubuntu 18.04 specific. </p>
<h2 id="Install-ROS1-Melodic"><a href="#Install-ROS1-Melodic" class="headerlink" title="Install ROS1 - Melodic"></a>Install ROS1 - Melodic</h2><h3 id="Setup-sources-list"><a href="#Setup-sources-list" class="headerlink" title="Setup sources.list"></a>Setup sources.list</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sh -c &#x27;echo &quot;deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list&#x27;</span><br></pre></td></tr></table></figure>



<h3 id="Set-up-keys"><a href="#Set-up-keys" class="headerlink" title="Set up keys"></a>Set up keys</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install curl # if you haven&#x27;t already installed curl</span><br><span class="line">curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add -</span><br></pre></td></tr></table></figure>

<h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install ros-melodic-desktop-full</span><br></pre></td></tr></table></figure>

<h3 id="Source-ROS-environment"><a href="#Source-ROS-environment" class="headerlink" title="Source ROS environment"></a>Source ROS environment</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;source /opt/ros/melodic/setup.bash&quot; &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="Install-Additional-Dependencies-for-managing-workspaces"><a href="#Install-Additional-Dependencies-for-managing-workspaces" class="headerlink" title="Install Additional Dependencies for managing workspaces"></a>Install Additional Dependencies for managing workspaces</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python-rosdep python-rosinstall python-rosinstall-generator python-wstool build-essential</span><br></pre></td></tr></table></figure>

<h3 id="Install-and-initilize-rosdep-to-help-resolve-package-dependencies"><a href="#Install-and-initilize-rosdep-to-help-resolve-package-dependencies" class="headerlink" title="Install and initilize rosdep to help resolve package dependencies"></a>Install and initilize rosdep to help resolve package dependencies</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python-rosdep</span><br><span class="line">sudo rosdep init</span><br><span class="line">rosdep update</span><br></pre></td></tr></table></figure>

<h3 id="Verify-installation-by-running-RViz-visualization-GUI"><a href="#Verify-installation-by-running-RViz-visualization-GUI" class="headerlink" title="Verify installation by running RViz (visualization GUI)"></a>Verify installation by running RViz (visualization GUI)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rviz</span><br></pre></td></tr></table></figure>



<p><a target="_blank" rel="noopener" href="https://wiki.ros.org/melodic/Installation/Ubuntu">Reference</a></p>
<h2 id="Install-ROS2-Dashing"><a href="#Install-ROS2-Dashing" class="headerlink" title="Install ROS2 - Dashing"></a>Install ROS2 - Dashing</h2><h3 id="Install-host-operating-system-dependencies"><a href="#Install-host-operating-system-dependencies" class="headerlink" title="Install host operating system dependencies"></a>Install host operating system dependencies</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install usbutils git bc</span><br><span class="line">sudo apt-get -y install locales</span><br><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install curl gnupg2 lsb-release</span><br></pre></td></tr></table></figure>



<h3 id="Setup-sources-list-1"><a href="#Setup-sources-list-1" class="headerlink" title="Setup sources.list"></a>Setup sources.list</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sh -c &#x27;echo &quot;deb [arch=amd64,arm64] http://packages.ros.org/ros2/ubuntu `lsb_release -cs` main&quot; &gt; /etc/apt/sources.list.d/ros2-latest.list&#x27;</span><br></pre></td></tr></table></figure>



<h3 id="Set-up-keys-1"><a href="#Set-up-keys-1" class="headerlink" title="Set up keys"></a>Set up keys</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys F42ED6FBAB17C654</span><br></pre></td></tr></table></figure>

<h3 id="Install-1"><a href="#Install-1" class="headerlink" title="Install"></a>Install</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install ros-dashing-desktop</span><br></pre></td></tr></table></figure>

<h3 id="Source-ROS-environment-1"><a href="#Source-ROS-environment-1" class="headerlink" title="Source ROS environment"></a>Source ROS environment</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;source /opt/ros/dashing/setup.bash&quot; &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="Install-Additional-Dependencies-for-managing-workspaces-1"><a href="#Install-Additional-Dependencies-for-managing-workspaces-1" class="headerlink" title="Install Additional Dependencies for managing workspaces"></a>Install Additional Dependencies for managing workspaces</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python3-argcomplete</span><br><span class="line">sudo apt-get install python3-colcon-common-extensions</span><br></pre></td></tr></table></figure>

<h3 id="Verify-installation-by-running-Rviz2-visualization-GUI"><a href="#Verify-installation-by-running-Rviz2-visualization-GUI" class="headerlink" title="Verify installation by running Rviz2 (visualization GUI)"></a>Verify installation by running Rviz2 (visualization GUI)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rviz2</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/quick-start-guide/qualcomm_robotics_rb5_development_kit_bring_up/run-a-basic-ROS2-application">Reference</a></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/RB5_Robotics_Tutorials/2022/05/21/3%20Robotics%20Applications/ros-installation/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/RB5_Robotics_Tutorials/2022/05/18/1%20Initial%20Set-up/visualization-tools/"
                            aria-label=": (2) Visualization Tools"
                        >
                            (2) Visualization Tools
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2022-05-18T17:12:21-07:00">
	
		    May 18, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/1-Initial-Set-up/">1 Initial Set-up</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>Getting a gnome desktop is desirable for its more familiar to most of us compared to the default wayland desktop. </p>
<p>To get the gnome desktop, you will need to unminimize the system first. The current system is a minimal ubuntu 18.04 server and you can unminimize it to add more tools.</p>
<p>Then you can start install the gnome desktop by the following commands:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt install gdm3 tasksel</span><br><span class="line">tasksel install ubuntu-desktop</span><br></pre></td></tr></table></figure>

<p>When this is done, you need to run the following command everytime you want to us the gnome desktop.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service gdm3 start</span><br></pre></td></tr></table></figure>

<p>Notice that in order to successfully login to the gnome desktop, make use you choose the wayland for ubuntu in the login page, otherwise your username and password might not work.</p>
<p>Notice that even we have this gnome desktop, many gui applications with x11 support might still not work. However, the gnome-terminal and RViz will work properly.</p>
<p>Also, we do not recommand use this desktop because it takes a lot of computation (300-400% cpu!!!). It should only be used for visualization and debugging purpose for a short period of time.</p>
<p>Reference:<br>[1] <a target="_blank" rel="noopener" href="https://linuxconfig.org/how-to-install-gnome-on-ubuntu-18-04-bionic-beaver-linux">https://linuxconfig.org/how-to-install-gnome-on-ubuntu-18-04-bionic-beaver-linux</a></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/RB5_Robotics_Tutorials/2022/05/18/1%20Initial%20Set-up/visualization-tools/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/RB5_Robotics_Tutorials/2022/05/18/2%20Accessing%20Devices/building-and-loading-kernel-modules/"
                            aria-label=": (2) Building and Loading Kernel Modules"
                        >
                            (2) Building and Loading Kernel Modules
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2022-05-18T17:12:21-07:00">
	
		    May 18, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/2-Accessing-Devices/">2 Accessing Devices</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>The LU build outlined during in the <a href="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/1%20Initial%20Set-up/bring-up-rb5/">bring-up process</a> comprises of a minimal Ubuntu 18.04 installation. For this reason, various device kernel modules need to be build from source and loaded. In this tutorial, we document the process of building and loading the kernel modules for a USB joystick (<strong>joydev</strong>) and USB over serial (<strong>ch341</strong>). The source code associated with these modules is open-source and available as part of the <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux">linux kernel</a>.</p>
<h3 id="joydev"><a href="#joydev" class="headerlink" title="joydev"></a>joydev</h3><p>The kernel version utilized for this tutorial corresponds to <code>4.19.125</code>. If a different version is being used, you can find the version that matches your kernel by utilizing <code>uname -r</code>.</p>
<p>Extract the source code associated with this module</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.19.125.tar.gz</span><br><span class="line">tar xvzf linux-4.19.125.tar.gz </span><br><span class="line">cp -r linux-4.19.125/drivers/input /temp/dir &amp;&amp; cd /temp/dir/input</span><br></pre></td></tr></table></figure>

<p>The following changes need to be made to the Makefile that was copied to <code>/temp/dir/input</code>.</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">KVERS = <span class="variable">$(<span class="built_in">shell</span> uname -r)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kernel modules</span></span><br><span class="line">obj-m := joydev.o</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">EXTRA_CFLAGS=-g -O0 -Wno-vla -Wframe-larger-than=4496</span><br><span class="line"></span><br><span class="line"><span class="section">build: kernel_modules</span></span><br><span class="line"></span><br><span class="line"><span class="section">kernel_modules:</span></span><br><span class="line">	make -C /usr/src/header M=<span class="variable">$(CURDIR)</span> modules</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">	make -C /usr/src/header M=<span class="variable">$(CURDIR)</span> clean</span><br></pre></td></tr></table></figure>

<p>Build and Load kernel module</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make</span><br><span class="line">insmod joydev.ko</span><br></pre></td></tr></table></figure>

<p>To avoid loading the module every time, the following script can be utlized.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">KERNEL_VERSION=$(uname -r)</span><br><span class="line">MODINFO=$(modinfo ./joydev/joydev.ko | grep vermagic)</span><br><span class="line">MODULE_VERSION=$(echo $MODINFO | cut -d &quot; &quot; -f 2) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ $KERNEL_VERSION != $MODULE_VERSION ]</span><br><span class="line">then</span><br><span class="line">  echo &quot;Versions incompatible&quot;</span><br><span class="line">  echo &quot;.ko file compiled with &quot; $MODULE_VERSION</span><br><span class="line">  echo &quot;System kernel is &quot; $KERNEL_VERSION</span><br><span class="line">else</span><br><span class="line">  cp ./joydev/joydev.ko /lib/modules/$(uname -r)/kernel/drivers/input</span><br><span class="line">  depmod -a</span><br><span class="line">  echo &quot;JOYDEV loaded&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>



<h3 id="ch341"><a href="#ch341" class="headerlink" title="ch341"></a>ch341</h3><p>Extract the source code associated with this module</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.19.125.tar.gz</span><br><span class="line">tar xvzf linux-4.19.125.tar.gz </span><br><span class="line">cp linux-4.19.125/drivers/usb/serial &amp;&amp; cd /temp/dir/input</span><br></pre></td></tr></table></figure>

<p>The following changes need to be made to the Makefile that was copied to <code>/temp/dir/input</code>.</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">KVERS = <span class="variable">$(<span class="built_in">shell</span> uname -r)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kernel modules</span></span><br><span class="line">obj-m := ch341.o</span><br><span class="line"></span><br><span class="line">EXTRA_CFLAGS=-g -O0 -Wno-vla</span><br><span class="line"></span><br><span class="line"><span class="section">build: kernel_modules</span></span><br><span class="line"></span><br><span class="line"><span class="section">kernel_modules:</span></span><br><span class="line">	make -C /usr/src/header M=<span class="variable">$(CURDIR)</span> modules</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">	make -C /usr/src/header M=<span class="variable">$(CURDIR)</span> clean</span><br></pre></td></tr></table></figure>

<p>Build and Load kernel module</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make</span><br><span class="line">insmod ch341.ko</span><br></pre></td></tr></table></figure>

<p>To avoid loading the module every time, the following script can be utlized.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">KERNEL_VERSION=$(uname -r)</span><br><span class="line">MODINFO=$(modinfo ./ch341/ch341.ko | grep vermagic)</span><br><span class="line">MODULE_VERSION=$(echo $MODINFO | cut -d &quot; &quot; -f 2) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ $KERNEL_VERSION != $MODULE_VERSION ]</span><br><span class="line">then</span><br><span class="line">  echo &quot;Versions incompatible&quot;</span><br><span class="line">  echo &quot;.ko file compiled with &quot; $MODULE_VERSION</span><br><span class="line">  echo &quot;System kernel is &quot; $KERNEL_VERSION</span><br><span class="line">else</span><br><span class="line">  cp ./ch341/ch341.ko /lib/modules/$(uname -r)/kernel/drivers/usb/serial</span><br><span class="line">  depmod -a</span><br><span class="line">  echo &quot;CH341 loaded&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>



<p>The Makefiles and kernel modules can be found on <a target="_blank" rel="noopener" href="https://github.com/AutonomousVehicleLaboratory/rb5_lib">Github</a>.</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/RB5_Robotics_Tutorials/2022/05/18/2%20Accessing%20Devices/building-and-loading-kernel-modules/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/RB5_Robotics_Tutorials/2022/05/18/3%20Robotics%20Applications/setup-orb-slam3-on-rb5/"
                            aria-label=": (3) Setup ORB_SLAM3 on RB5"
                        >
                            (3) Setup ORB_SLAM3 on RB5
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2022-05-18T17:12:21-07:00">
	
		    May 18, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/3-Robotics-Applications/">3 Robotics Applications</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>This tutorial will guide you towards running ORB_SLAM3 on RB5.</p>
<p>The code from ORB_SLAM3 original repository doesn’t work right out of box on RB5. We created a version that we tested on RB5 and works well. You can download the code from <a target="_blank" rel="noopener" href="https://github.com/AutonomousVehicleLaboratory/ORB_SLAM3_RB5">https://github.com/AutonomousVehicleLaboratory/ORB_SLAM3_RB5</a>.</p>
<p>After downloading the code, follow the README.md to compile the ORB_SLAM3 library and ROS nodes. When running the ROS node, you will need to access camera using the ROS package we mentioned in the basic tutorial accessing cameras <a href="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/15/1%20Basic%20Tutorials/accessing-camera-on-rb5/">https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/15/1%20Basic%20Tutorials/accessing-camera-on-rb5/</a>.</p>
<p>The current version allows you to run the Monocular version of ORB-SLAM3 on RB5. The text interface will work with wayland desktop.</p>
<div class="figure " style="width:;"><img class="fig-img" src="ORB-SLAM3-Gnome-Terminal.png" alt="ORB-SLAM3 running in a Gnome-Terminal"><span class="caption">ORB-SLAM3 running in a Gnome-Terminal</span></div>

<p>You can also launch RViz on the gnome desktop that you setup following the tutorial: <a href="https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/1%20Basic%20Tutorials/setup-gnome-desktop-on-rb5/">https://autonomousvehiclelaboratory.github.io/RB5_Robotics_Tutorials/2022/02/13/1%20Basic%20Tutorials/setup-gnome-desktop-on-rb5/</a>.</p>
<div class="figure " style="width:;"><img class="fig-img" src="ORB-SLAM3-RViz.png" alt="ORB-SLAM3 pose displayed in RViz"><span class="caption">ORB-SLAM3 pose displayed in RViz</span></div>
                    
                        


                    
                    
                        <p>
                            <a
                                href="/RB5_Robotics_Tutorials/2022/05/18/3%20Robotics%20Applications/setup-orb-slam3-on-rb5/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/"
                            aria-label=": (1) Running DeepLabV3 Model"
                        >
                            (1) Running DeepLabV3 Model
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2022-05-18T17:12:21-07:00">
	
		    May 18, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/4-ML-at-the-Edge/">4 ML at the Edge</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>This tutorial explains the process of setting up the SNPE SDK and running inference on RB5 using a TensorFlow and PyTorch segmentation model. </p>
<p>Note: This can be extended to any Deep Learning models</p>
<h2 id="TesnorFlow"><a href="#TesnorFlow" class="headerlink" title="TesnorFlow"></a>TesnorFlow</h2><h3 id="Running-Inference-on-Ubuntu-18-0-4"><a href="#Running-Inference-on-Ubuntu-18-0-4" class="headerlink" title="Running Inference on Ubuntu 18.0.4:"></a>Running Inference on Ubuntu 18.0.4:</h3><p>This section will guide you in setting up the SNPE on a Ubuntu system and running inference using the TensorFlow model for DeepLabV3</p>
<ol>
<li>Download pre-trained DeepLabV3 model trained using TensorFlow:</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.tensorflow.org/modelsdeeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz</span><br><span class="line">tar -xzvf deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Setup Qualcomm Snapdragon Neural Processing Engine SDK on the system using the tutorial mentioned below.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo snap install --classic android-studio #Android Studio installation is necessary for SNPE SDK to work</span><br><span class="line">https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk/getting-started</span><br></pre></td></tr></table></figure>
<p>Note: Make sure all the path variables are set properly according to the tutorial provided in the above links. Failing to set the paths will result in the following command to fail.</p>
<ol start="3">
<li>Set the environment path for TensorFlow</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd $SNPE_ROOT</span><br><span class="line">export TENSORFLOW_DIR=&quot;your_tensorflow_installation_dir&quot;</span><br><span class="line">source bin/envsetup.sh -o $TENSORFLOW_DIR</span><br></pre></td></tr></table></figure>


<ol start="4">
<li>Convert the model to .dlc format using the following command</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snpe-tensorflow-to-dlc --input_dim sub_7 1,513,513,3 --out_node ArgMax --input_network ./deeplabv3_mnv2_pascal_train_aug/frozen_inference_graph.pb</span><br></pre></td></tr></table></figure>
<p>Note: The “.&#x2F;deeplabv3_mnv2_pascal_train_aug&#x2F;frozen_inference_graph.pb” is the downloaded TF model and the image size is set to 513x513x3 as an example</p>
<ol start="5">
<li>Running Inference:</li>
</ol>
<ul>
<li><p>Preprocess the image using the Python script below. Example image is provided.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line">frame = cv2.imread(&#x27;Example.jpeg&#x27;)</span><br><span class="line"># Resize frame with Required image size</span><br><span class="line">frame_resized = cv2.resize(frame,(513,513))</span><br><span class="line"># Pad smaller dimensions to Mean value &amp; Multiply with 0.007843</span><br><span class="line">blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (513, 513), (127.5, 127.5, 127.5), swapRB=True)</span><br><span class="line"></span><br><span class="line"># Making numpy array of required shape</span><br><span class="line">blob = np.reshape(blob, (1,513,513,3))</span><br><span class="line"></span><br><span class="line"># Storing to a raw file</span><br><span class="line">np.ndarray.tofile(blob, open(&#x27;blob.raw&#x27;,&#x27;w&#x27;) )</span><br></pre></td></tr></table></figure>
</li>
<li><p>Prepare a text file that contains all the images you would like to run inference on</p>
<ul>
<li>Create a file names “raw_list.txt” in the current directory</li>
<li>Enter the path of the “blob.raw” file that was generated using the Python script</li>
</ul>
</li>
<li><p>Run the following command to use the generated dlc model to run inference</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snpe-net-run --container deeplabv3.dlc --input_list ./raw_list.txt</span><br></pre></td></tr></table></figure>
<p>This command generates a file called “ArgMax:0.raw” in “&#x2F;output&#x2F;Result_0&#x2F;” path that will be used as an input to out model.</p>
<ul>
<li>Run the input below Python script to obtain the segmentation masks and modify the image</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line">arr = np.fromfile(open(&#x27;ArgMax:0.raw&#x27;, &#x27;r&#x27;), dtype=&quot;float32&quot;)</span><br><span class="line">arr = np.reshape(arr, (513,513,1))</span><br><span class="line">segment = arr[342:, 342:]</span><br><span class="line">arr[arr == 15] = 255</span><br><span class="line">original_img = cv2.imread(&#x27;deeplab-check.jpeg&#x27;)</span><br><span class="line">arr2=cv2.resize(segment,(original_img.shape[1], original_img.shape[0]))</span><br><span class="line">print(arr.shape)</span><br><span class="line">for i in range(arr2.shape[0]):</span><br><span class="line">    for j in range(arr2.shape[1]):</span><br><span class="line">        if (arr2[i][j] != 255):</span><br><span class="line">            original_img[i][j] = original_img[i][j][0] = original_img[i][j][1] = original_img[i][j][2]</span><br><span class="line">plt.imshow(original_img)</span><br><span class="line">plt.show()</span><br><span class="line">plt.imshow( arr, cmap=&quot;gray&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="Running-Inference-on-RB5"><a href="#Running-Inference-on-RB5" class="headerlink" title="Running Inference on RB5:"></a>Running Inference on RB5:</h3><p>The SNPE SDK provides binaries for RB5’s architecture. To check out the list of supported architectures, run</p>
<h4 id="On-Ubuntu"><a href="#On-Ubuntu" class="headerlink" title="On Ubuntu:"></a>On Ubuntu:</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $SNPE_ROOT/lib #Ensure the path export from SNPE installation</span><br><span class="line">ls</span><br></pre></td></tr></table></figure>

<p>For the Qualcomm RB5 platform, we are interested in in the following folders:</p>
<ul>
<li>aarch64-ubuntu-gcc7.5</li>
<li>dsp</li>
</ul>
<p>These folders need to be copied over to the RB5 either by using “adb shell”, “adb push” or “scp” commands.</p>
<ol>
<li>Select the architecture aarch64-ubuntu-gcc7.5</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export SNPE_TARGET_ARCH=aarch64-ubuntu-gcc7.5</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Push the binaries to target</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">adb shell &quot;mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin&quot; # Creates a folder with the architecture&#x27;s name</span><br><span class="line">adb shell &quot;mkdir -p /data/local/tmp/snpeexample/dsp/lib&quot; #Creates lib folder to copy over the libraries to</span><br><span class="line">adb push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib #Copy the architecture libraries</span><br><span class="line">adb push $SNPE_ROOT/lib/dsp/*.so  /data/local/tmp/snpeexample/dsp/lib</span><br><span class="line">adb push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin</span><br></pre></td></tr></table></figure>

<p>Once the libraries are copied over, log into RB5 using “adb shell” command or use a monitor(preferred as the final result involves visualizing)</p>
<h4 id="On-RB5"><a href="#On-RB5" class="headerlink" title="On RB5:"></a>On RB5:</h4><ol>
<li>Set tup the target architecture, library path and environment variables for “snpe-net-run” command to run successfully</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export SNPE_TARGET_ARCH=aarch64-ubuntu-gcc7.5</span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib</span><br><span class="line">export PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin</span><br></pre></td></tr></table></figure>

<p>Note: These commands need to be run everytime a new terminal is opened. To avoid this, add these commands in ~&#x2F;.bashrc file and run “source ~&#x2F;.bashrc”</p>
<ol start="2">
<li>Verify snpe-net-run copy</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snpe-net-run -h #This command should run successfully and list the available options</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>Copy the Python scripts and the “.dlc” file and the images from “Running Inference on Ubuntu 18.0.4” section to run inference</p>
</li>
<li><p>Follow Step 4 from the previous section to run inference. (Feel free to skip the blob.raw generation if it is already copied over)</p>
</li>
</ol>
<p>Note: The inference step involves running “snpe-net-run”.</p>
<p>Note: Once the masks are obtained, it can be used for any application. We have shown a simple background blur in this example.</p>
<h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><p>A PyTorch model can be converted to dlc format to be run on RB5 as mentioned in the following sections. </p>
<p>Important: PyTorch models need to be converted to ONNX before they are converted to dlc format.</p>
<ol>
<li>Run the following script to generate DeepLabV3 ONNX model. Here we use pre-trained DeepLabV3 model available in TorchHub</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">BEST_MODEL_PATH_ONNX = &quot;deeplabv3_onnx_model.onnx&quot;</span><br><span class="line">#Load pre-trained Model</span><br><span class="line">model = torch.hub.load(&#x27;pytorch/vision:v0.7.0&#x27;, &#x27;deeplabv3_resnet50&#x27;, pretrained=True)</span><br><span class="line">model.eval()</span><br><span class="line">x = torch.randn(1, 3, 224, 224, requires_grad=True)</span><br><span class="line">y = model(x)</span><br><span class="line">torch_out = torch.onnx._export(model,                   # model being run</span><br><span class="line">                                x,                      # model input (or a tuple for multiple inputs)</span><br><span class="line">                                BEST_MODEL_PATH_ONNX,   # where to save the model (can be a file or file-like object)</span><br><span class="line">                                export_params=True,     # store the trained parameter weights inside the model file</span><br><span class="line">                                input_names=[&#x27;Conv2d0_3-64&#x27;],     # specify the name of input layer in onnx model</span><br><span class="line">                                output_names=[&#x27;Linear2_4096-2&#x27;])    # specify the name of output layer</span><br><span class="line">print(&quot;Successfully genereated ONNX model at &quot;,BEST_MODEL_PATH_ONNX)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Install ONNX on Ubuntu system</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install onnx</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Set the environment path for ONNX</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd $SNPE_ROOT</span><br><span class="line">export ONNX_DIR=&quot;your_onnx_installation_dir&quot;</span><br><span class="line">source bin/envsetup.sh -o $ONNX_DIR</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>Run ONNX to DLC conversion command</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snpe-onnx-to-dlc --input_dim sub_7 1,513,513,3 --out_node ArgMax --input_network /deeplabv3_onnx_model.onnx --output_path deeplab_pt.dlc</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>Once the dlc format is generated successfully, follow the “Running Inference” sections in TensorFlow section to run inference on both Ubuntu and RB5</li>
</ol>
<div class="figure " style="width:;"><img class="fig-img" src="Example.png" alt="Example Input Image"><span class="caption">Example Input Image</span></div>

<div class="figure " style="width:;"><img class="fig-img" src="Mask.png" alt="Generated Mask"><span class="caption">Generated Mask</span></div>

<div class="figure " style="width:;"><img class="fig-img" src="PostProcessed.png" alt="Post Processed Image"><span class="caption">Post Processed Image</span></div>


                    
                        


                    
                    
                        <p>
                            <a
                                href="/RB5_Robotics_Tutorials/2022/05/18/4%20ML%20at%20the%20Edge/DeepLabV3-using-TensorFlow/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/RB5_Robotics_Tutorials/2022/02/15/2%20Accessing%20Devices/accessing-camera-on-rb5/"
                            aria-label=": (1) Accessing Camera on RB5"
                        >
                            (1) Accessing Camera on RB5
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2022-02-15T17:12:21-08:00">
	
		    Feb 15, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/2-Accessing-Devices/">2 Accessing Devices</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>A key sensor for many robotics applications is camera. It enables cool applications such as object detection, semantic segmentation and visual SLAM. There are two cameras on RB5.</p>
<p>This tutorial will tell you a few ways to access these cameras. Before we start, note that these cameras cannot be read from OpenCV directly but a tool called GStreamer can bridge the gap.</p>
<p>The easiest way to access camera is through a tcp port created by GStreamer. Then you can use OpenCV to read data from the tcp port.</p>
<p>On RB5, run the following command:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gst-launch-1.0 -e qtiqmmfsrc name=qmmf ! video/x-h264,format=NV12, width=1280, height=720,framerate=30/1 ! h264parse config-interval=1 ! mpegtsmux name=muxer ! queue ! tcpserversink port=8900 host=192.168.1.120</span><br></pre></td></tr></table></figure>

<p>Note that you will need to change the host ip to your RB5 ip address. This can be done by running the following command.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install net-tools # if you don&#x27;t have ifconfig</span><br><span class="line">ifconfig</span><br></pre></td></tr></table></figure>

<p>The ip address of RB5 can be found after inet as something like 192.168.0.xxx.</p>
<p>Then you can access the camera with the help of the OpenCV library. A python example is given below</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">cap = cv2.VideoCapture(&quot;tcp://192.168.1.120:8900&quot;) #rb5 ip &amp; port (same from command)</span><br><span class="line">while(True):</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    cv2.imwrite(&quot;captured_image_opencv.jpg&quot;,frame)</span><br><span class="line">    # you can process image by using frame </span><br><span class="line">    break</span><br><span class="line">cap.release()</span><br></pre></td></tr></table></figure>

<p>Again, make sure you change the host ip to your RB5 ip.</p>
<p>Another way is to use the ROS package we provided both in ROS1 and ROS2.</p>
<p>ROS1: <a target="_blank" rel="noopener" href="https://github.com/AutonomousVehicleLaboratory/rb5_ros/tree/main/rb5_vision">https://github.com/AutonomousVehicleLaboratory/rb5_ros/tree/main/rb5_vision</a><br>ROS2: <a target="_blank" rel="noopener" href="https://github.com/AutonomousVehicleLaboratory/rb5_ros2/tree/main/rb5_ros2_vision">https://github.com/AutonomousVehicleLaboratory/rb5_ros2/tree/main/rb5_ros2_vision</a></p>
<p>Reference:<br>[1]: <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/comment/18637#comment-18637">https://developer.qualcomm.com/comment/18637#comment-18637</a></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/RB5_Robotics_Tutorials/2022/02/15/2%20Accessing%20Devices/accessing-camera-on-rb5/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/RB5_Robotics_Tutorials/2022/02/13/1%20Initial%20Set-up/bring-up-rb5/"
                            aria-label=": (1) Bring Up RB5"
                        >
                            (1) Bring Up RB5
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2022-02-13T17:12:21-08:00">
	
		    Feb 13, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/1-Initial-Set-up/">1 Initial Set-up</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>RB5 is a powerful edge computing device for robotics applications. Before we can use it to drive cool applications, we need to flash an operating system into it. In this tutorial, we will show you how to set up Ubuntu 18.04 on RB5 and connect it to WiFi to enable SSH. We enhanced the <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/quick-start-guide/qualcomm_robotics_rb5_development_kit_bring_up">official setup guide</a> with some additional tips. The setup steps requires a computer with Ubuntu operating system. </p>
<h2 id="Install-Ubuntu-18-04-on-RB5"><a href="#Install-Ubuntu-18-04-on-RB5" class="headerlink" title="Install Ubuntu 18.04 on RB5"></a>Install Ubuntu 18.04 on RB5</h2><p>a) Install adb and fastboot by using the following command in Linux Terminal: </p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install android-tools-adb android-tools-fastboot</span><br></pre></td></tr></table></figure>

<p>b) Download the Qualcomm Robotics SDK Manager from <a target="_blank" rel="noopener" href="https://www.thundercomm.com/product/qualcomm-robotics-rb5-development-kit/#sdk-manager">here</a>. You will need to create an account for this.</p>
<p>c) The download should be a Zip file that contains the SDK Manager installation package and a Readme file. Follow the instructions in the Readme file to install the prerequisites.</p>
<p>d) Install the SDK manager on the Linux workstation. Refer to the process given as step 2 in the following <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/quick-start-guide/qualcomm_robotics_rb5_development_kit_bring_up/download-and-install-the-SDK-manager">link</a></p>
<p>e) <strong>Before running the SDK manager, if you are using a Linux workstation, run the following command in the Terminal</strong>: </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop ModemManager</span><br></pre></td></tr></table></figure>

<p>f) Run the SDK manager. Follow step 3 in the following <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/quick-start-guide/qualcomm_robotics_rb5_development_kit_bring_up/download-and-install-the-SDK-manager">link</a></p>
<p>g) Follow step 4 from the same <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/quick-start-guide/qualcomm_robotics_rb5_development_kit_bring_up/download-and-install-the-SDK-manager">link</a> to download resources and generate system image. This could take slightly more than 30 minutes. </p>
<p>h) Choose LU or LE flash. The LU flash has been tried before and flash was a success. This <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/comment/18517">forum answer</a> is a possible explanation for the difference between LU and LE flash.</p>
<p>i) Now, start the process of flashing the generated system images on the RB5 by following step 5 from the same <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/quick-start-guide/qualcomm_robotics_rb5_development_kit_bring_up/download-and-install-the-SDK-manager">link</a></p>
<p>j) Follow steps 1-3 from this <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/quick-start-guide/qualcomm_robotics_rb5_development_kit_bring_up/flash-images">link</a> to continue and complete the flashing process successfully.</p>
<p>k) If flashing is successful, adb should be working. To check this, keep your RB5 connected to your workstation and open your workstation’s terminal and type: </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">adb shell</span><br></pre></td></tr></table></figure>
<p>and you should see a device ID shown as an attached device.</p>
<p>l) If not, please power cycle the development kit. Since the system images are flashed, there is no need to press the F_DL key to force the device to enter the Emergency Download Mode.</p>
<h2 id="Setup-WiFi-and-SSH"><a href="#Setup-WiFi-and-SSH" class="headerlink" title="Setup WiFi and SSH"></a>Setup WiFi and SSH</h2><p>Once the OS is flashed, the next step involves setting up WiFi and SSH connections.<br>To set up WiFi connectivity on RB5, follow steps 1-4 from this <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/quick-start-guide/qualcomm_robotics_rb5_development_kit_bring_up/set-up-network">link</a></p>
<p>To access RB5 terminal, both adb shell or SSH can be used. To set up SSH connection:</p>
<p>a) Type the following commands in a new terminal:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">adb shell  </span><br><span class="line">sh-4.4#ifconfig </span><br></pre></td></tr></table></figure>
<p>The ‘ifconfig’ command gives you the IP address of your connection.<br>  Then use the following command:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh-4.4#ssh root@ &lt;IP address&gt;</span><br></pre></td></tr></table></figure>
<p> This will ask you for a password, which is ‘oelinux123’</p>
<p>This will successfully complete the SSH connection, through which you can remotely access the RB5 terminal.</p>
<p>The next step involves connecting to an HDMI monitor. The following is the procedure:</p>
<p>  a) Refer to the ‘Check HDMI’ section in this <a target="_blank" rel="noopener" href="https://developer.qualcomm.com/qualcomm-robotics-rb5-kit/quick-start-guide/qualcomm_robotics_rb5_development_kit_bring_up/set-up-network">link</a></p>
<p>  b) <strong>Instead of the 5 commands given in the link given in a), you could try just this single command after connecting the HDMI</strong>:<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weston --connector=29</span><br></pre></td></tr></table></figure><br>  c) If b) doesn’t work, then use the following 5 commands everytime while connecting HDMI:<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c:\&gt;adb shell</span><br><span class="line">sh-4.4# mkdir -p /usr/bin/weston_socket</span><br><span class="line">sh-4.4# export XDG_RUNTIME_DIR=/usr/bin/weston_socket</span><br><span class="line">sh-4.4# export LD_LIBRARY_PATH=/usr/lib:/usr/lib/aarch64-linux-gnu/</span><br><span class="line">sh-4.4# weston --tty=1 --connector=29 --idle-time=0</span><br></pre></td></tr></table></figure></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/RB5_Robotics_Tutorials/2022/02/13/1%20Initial%20Set-up/bring-up-rb5/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/"
                            aria-label=": (2) April Tag Feature Detection"
                        >
                            (2) April Tag Feature Detection
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2022-02-13T17:12:21-08:00">
	
		    Feb 13, 2022
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/RB5_Robotics_Tutorials/categories/3-Robotics-Applications/">3 Robotics Applications</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <p>An important task in robotics is to uniquely identify features and landmarks over time as a robot navigates through the environment. The process can help estimate the robotics position (localization) to ultimately be able to perform robust path planning and navigation. In this tutorial, we will explore a popular open-source library for AprilTag detection and 3D pose estimation from a single monorcular camera. </p>
<p>AprilTags (shown in the figure below) are a form of fiducial markers that are designed with predefined sizes and patterns. The benefit of knowing their size is pose estimation given that a perspective mapping between two planes can be described by a Homography $\mathbf{H}$ matrix. In this case, $\mathbf{H}$ can describe a mapping between the camera frame and the marker since both can be assumed to be flat surfaces. This makes AprilTags an easy way of performing 3D pose estimation of objects with a single monocular camera by simply placing an AprilTag on the object. In addition, the unique pattern that defines each marker can help differentiate multiple markers that may be observable at a particular instance and by leveraging the concept of Hamming distance and dictionaries, error detection and correction can be performed in the event that part of a marker is occluded.</p>
<div class="figure " style="width:;"><img class="fig-img" src="apriltags.png" alt="Multiple AprilTag fiducial markers detected within an image with IDs 7 and 237. For marker 7, an error is detected and corrected. [1]"><span class="caption">Multiple AprilTag fiducial markers detected within an image with IDs 7 and 237. For marker 7, an error is detected and corrected. [1]</span></div>
<h2 id="The-AprilTag3-Library"><a href="#The-AprilTag3-Library" class="headerlink" title="The AprilTag3 Library"></a>The AprilTag3 Library</h2><p>Using the AprilTag library is actually quite simple and can be installed from <a target="_blank" rel="noopener" href="https://github.com/AprilRobotics/apriltag">source</a>. This includes compatible versions for C++ but also Python3. While our implementation will consist of C++, the Python version is even easier to get up and running. To install, simply run <code>pip install apriltag</code>.</p>
<p>For convenience, we have provided two implementations for AprilTag detection in ROS1 and ROS2. Given that both are C++ implementations, the logic remains the same. First, we convert our image to grayscale and populate a <code>image_u8_t</code> struct using the OpenCV <code>cv::Mat</code> image format. </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cv::Mat image_gray; </span><br><span class="line">cv::<span class="built_in">cvtColor</span>(image, image_gray, cv::COLOR_BGR2GRAY);</span><br><span class="line"></span><br><span class="line"><span class="type">image_u8_t</span> im = &#123; .width  = image_gray.cols,</span><br><span class="line">.height = image_gray.rows,</span><br><span class="line">.stride = image_gray.cols, </span><br><span class="line">.buf    = image_gray.data </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p> Once the image has been converted to grayscale, we can instantiate an <code>apriltag_detection_t</code> instance and call <code>apriltag_detector_detect()</code>. This is the primary function incharge of performing marker detection on camera data. It is worth noting that this detection object can be reused so memory can be allocated in the class constructor of your implementation.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">apriltag_detector_t</span> *a_detector = <span class="built_in">apriltag_detector_create</span>();</span><br><span class="line"><span class="type">zarray_t</span> * detections = <span class="built_in">apriltag_detector_detect</span>(a_detector, &amp;im);</span><br></pre></td></tr></table></figure>

<p>As it can be seen, <code>apriltag_detector_detect()</code> returns an array of type <code>zarray_t</code> with the list of detections concatenated. In the following code block we extract individual detections into instances of type <code>apriltag_detection_t</code> and perform a perspective mapping using the homography matrix calculated. This is handled by <code>estimate_tag_pose()</code>. However, two important considerations include <em>i)</em> that we know the size of the markers in advance, and <em>ii)</em> we understand the intrinsic parameters of the camera that include image center and focal length. These are attributes that are part of the first argument of type <code>apriltag_detection_info_t</code> that is passed to <code>estimate_tag_pose()</code>. The marker size used in our implementation corresponds to $15.9cm$ and the camera parameters are estimated for the wide angle lens of the RB5 using the <a target="_blank" rel="noopener" href="https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html">OpenCV calibration tool</a> and a standard checkerboard target.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">apriltag_detection_t</span> *det;</span><br><span class="line"><span class="type">apriltag_detection_info_t</span> tag_info; </span><br><span class="line">vector&lt;<span class="type">apriltag_pose_t</span>&gt; poses;</span><br><span class="line">vector&lt;<span class="type">int</span>&gt; ids;</span><br><span class="line"></span><br><span class="line">tag_info.tagsize = <span class="number">0.159</span>;</span><br><span class="line">tag_info.fx = <span class="number">663.57507</span>; </span><br><span class="line">tag_info.fy = <span class="number">694.47272</span>;</span><br><span class="line">tag_info.cx = <span class="number">956.22994</span>;</span><br><span class="line">tag_info.cy = <span class="number">539.54574</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="built_in">zarray_size</span>(detections); i++)&#123;</span><br><span class="line">  <span class="built_in">zarray_get</span>(detections, i, &amp;det);</span><br><span class="line">  tag_info.det = det;</span><br><span class="line">  <span class="type">apriltag_pose_t</span> pose;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// estimate SE(3) pose </span></span><br><span class="line">  <span class="built_in">estimate_tag_pose</span>(&amp;tag_info, &amp;pose);</span><br><span class="line">  poses.<span class="built_in">push_back</span>(pose);</span><br><span class="line">  ids.<span class="built_in">push_back</span>(det-&gt;id);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The components described above have been wrapped into ROS1 and ROS2 implementations and be evaluated using the steps below.</p>
<h2 id="ROS1"><a href="#ROS1" class="headerlink" title="ROS1"></a>ROS1</h2><p>Create a workspace, clone the ROS1 implementation, and build the package. Make sure ROS is in your path, i.e. <code>source /opt/ros/melodic/setup.bash</code>. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p rb5_ws/src &amp;&amp; cd rb5_ws/src</span><br><span class="line">git clone https://github.com/AutonomousVehicleLaboratory/rb5_ros.git</span><br><span class="line">cd ..</span><br><span class="line">catkin_make</span><br><span class="line">source rb5_ws/devel/setup.bash </span><br></pre></td></tr></table></figure>

<p>Start the camera node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">roslaunch rb5_vision rb_camera_main_ocv.launch</span><br></pre></td></tr></table></figure>

<p>Start the AprilTag detection node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ros run april_detection april_detection_node</span><br></pre></td></tr></table></figure>



<h2 id="ROS2"><a href="#ROS2" class="headerlink" title="ROS2"></a>ROS2</h2><p>Create a workspace, clone the ROS2 implementation, and build the package. Make sure ROS is in your path, i.e. <code>source /opt/ros/dashing/setup.bash</code>. </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p rb5_ws/src &amp;&amp; cd rb5_ws/src</span><br><span class="line">git clone https://github.com/AutonomousVehicleLaboratory/rb5_ros2.git</span><br><span class="line">cd ..</span><br><span class="line">colcon build</span><br><span class="line">source rb5_ws/install/setup.bash </span><br></pre></td></tr></table></figure>

<p>Start the camera node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ros2 launch rb5_ros2_vision rb_camera_main_ocv_launch.py</span><br></pre></td></tr></table></figure>

<p>Start the AprilTag detection node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ros2 run ros2_april_detection april_detection_node</span><br></pre></td></tr></table></figure>



<h2 id="Visualizing-the-markers-and-poses"><a href="#Visualizing-the-markers-and-poses" class="headerlink" title="Visualizing the markers and poses"></a>Visualizing the markers and poses</h2><p>For convenience, our ROS implementations publish messages of type <code>geometry_msgs::PoseStamped</code> (<a target="_blank" rel="noopener" href="http://docs.ros.org/en/melodic/api/geometry_msgs/html/msg/PoseStamped.html">ROS1</a>) and <code>geometry_msgs::msg::PoseStamped</code> (<a target="_blank" rel="noopener" href="https://docs.ros2.org/foxy/api/geometry_msgs/msg/PoseStamped.html">ROS2</a>). These messages are timestamped and include a unique ID that corresponds to the marker ID as part of the message header. Nonetheless, the main component of each is message is the marker’s pose in 3D which is represented as a position (a point) and orientation (here represented as a Quaternion). While we won’t go into the math component on how Quaternions are utilized to represent orientations in 3D space, ROS has an good tools for handling transformation and can handle transformations with ease. Below is a video of each marker being visualized using the 3D visualization tool for ROS called RViz. The video demos AprilTag3 detection and real-time 3D pose estimation running onboard of Qualcomm RB5.</p>
<div class="video-container"><iframe src="https://www.youtube.com/embed/qRoW6ljBfFo" frameborder="0" loading="lazy" allowfullscreen></iframe></div>


<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a target="_blank" rel="noopener" href="https://april.eecs.umich.edu/media/pdfs/olson2011tags.pdf">AprilTag: A robust and flexible visual fiducial system</a></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="/RB5_Robotics_Tutorials/2022/02/13/3%20Robotics%20Applications/april-tag-feature-detection/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
        <li class="pagination-number">page 1 of 1</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2022 RB5 ROBOTICS TUTORIALS. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/RB5_Robotics_Tutorials/assets/images/avl-letters.png" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">RB5 ROBOTICS TUTORIALS</h4>
        
            <div id="about-card-bio"><p>A set of Robotics Tutorials developed for the RB5 Robotics Development Platform from Qualcomm. Authors are from the Contextual Robotics Institute at UC San Diego.</p>
</div>
        
        
            <div id="about-card-bio">
                <p>Contributors</p>

                <!-- <i class="fa fa-briefcase"></i>
                <br/> -->
                <p>Henrik I. Christensen, David Paz, Henry Zhang, Anirudh Ramesh.</p>

            </div>
        
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/RB5_Robotics_Tutorials/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/RB5_Robotics_Tutorials/assets/js/script-ouavugrvd9qj6lg3dktmularsze8hx0ahydxl4n9zvn5qystucng5rouil06.min.js"></script>

<!--SCRIPTS END-->





    </body>
</html>
